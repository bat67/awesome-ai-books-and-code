
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>chapter41</title><meta name="generator" content="MATLAB 8.0"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2013-08-21"><meta name="DC.source" content="chapter41.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, tt, code { font-size:12px; }
pre { margin:0px 0px 20px; }
pre.error { color:red; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">Matlab&#31070;&#32463;&#32593;&#32476;43&#20010;&#26696;&#20363;&#20998;&#26512;</a></li><li><a href="#2">&#28165;&#31354;&#29615;&#22659;&#21464;&#37327;</a></li><li><a href="#3">&#24314;&#31435;&#19968;&#20010;&#8220;&#31354;&#8221;&#31070;&#32463;&#32593;&#32476;</a></li><li><a href="#4">&#36755;&#20837;&#19982;&#32593;&#32476;&#23618;&#25968;&#23450;&#20041;</a></li><li><a href="#5">&#20351;&#29992;view(net)&#35266;&#23519;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#12290;</a></li><li><a href="#6">&#38408;&#20540;&#36830;&#25509;&#23450;&#20041;</a></li><li><a href="#7">&#36755;&#20837;&#19982;&#23618;&#36830;&#25509;&#23450;&#20041;</a></li><li><a href="#8">&#36755;&#20986;&#36830;&#25509;&#35774;&#32622;</a></li><li><a href="#9">&#36755;&#20837;&#35774;&#32622;</a></li><li><a href="#10">&#23618;&#35774;&#32622;</a></li><li><a href="#11">&#36755;&#20986;&#35774;&#32622;</a></li><li><a href="#12">&#38408;&#20540;&#65292;&#36755;&#20837;&#26435;&#20540;&#19982;&#23618;&#26435;&#20540;&#35774;&#32622;</a></li><li><a href="#13">&#23558;&#31070;&#32463;&#32593;&#32476;&#30340;&#26576;&#20123;&#26435;&#20540;&#30340;&#24310;&#36831;&#36827;&#34892;&#35774;&#32622;</a></li><li><a href="#14">&#32593;&#32476;&#20989;&#25968;&#35774;&#32622;</a></li><li><a href="#15">&#26435;&#20540;&#38408;&#20540;&#22823;&#23567;&#35774;&#32622;</a></li><li><a href="#16">&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;</a></li><li><a href="#17">&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;</a></li><li><a href="#18">&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21442;&#25968;</a></li><li><a href="#19">&#35757;&#32451;&#32593;&#32476;</a></li><li><a href="#20">&#20223;&#30495;&#26469;&#26816;&#26597;&#31070;&#32463;&#32593;&#32476;&#26159;&#21542;&#30456;&#24212;&#27491;&#24120;&#12290;</a></li></ul></div><h2>Matlab&#31070;&#32463;&#32593;&#32476;43&#20010;&#26696;&#20363;&#20998;&#26512;<a name="1"></a></h2><pre class="codeinput"><span class="comment">% &#23450;&#21046;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#29616;-&#31070;&#32463;&#32593;&#32476;&#30340;&#20010;&#24615;&#21270;&#24314;&#27169;&#19982;&#20223;&#30495;</span>
<span class="comment">% by &#29579;&#23567;&#24029;(@&#29579;&#23567;&#24029;_matlab)</span>
<span class="comment">% http://www.matlabsky.com</span>
<span class="comment">% Email:sina363@163.com</span>
<span class="comment">% http://weibo.com/hgsz2003</span>
</pre><h2>&#28165;&#31354;&#29615;&#22659;&#21464;&#37327;<a name="2"></a></h2><pre class="codeinput">clear <span class="string">all</span>
clc
warning <span class="string">off</span>
</pre><h2>&#24314;&#31435;&#19968;&#20010;&#8220;&#31354;&#8221;&#31070;&#32463;&#32593;&#32476;<a name="3"></a></h2><pre class="codeinput">net = network
</pre><pre class="codeoutput">
net =

    Neural Network
 
              name: 'Custom Neural Network'
        efficiency: .cacheDelayedInputs, .flattenTime,
                    .memoryReduction
          userdata: (your custom info)
 
    dimensions:
 
         numInputs: 0
         numLayers: 0
        numOutputs: 0
    numInputDelays: 0
    numLayerDelays: 0
 numFeedbackDelays: 0
 numWeightElements: 0
        sampleTime: 1
 
    connections:
 
       biasConnect: []
      inputConnect: []
      layerConnect: []
     outputConnect: []
 
    subobjects:
 
            inputs: {0x1 cell array of 0 inputs}
            layers: {0x1 cell array of 0 layers}
           outputs: {1x0 cell array of 0 outputs}
            biases: {0x1 cell array of 0 biases}
      inputWeights: {0x0 cell array of 0 weights}
      layerWeights: {0x0 cell array of 0 weights}
 
    functions:
 
          adaptFcn: (none)
        adaptParam: (none)
          derivFcn: 'defaultderiv'
         divideFcn: (none)
       divideParam: (none)
        divideMode: 'sample'
           initFcn: 'initlay'
        performFcn: 'mse'
      performParam: .regularization, .normalization
          plotFcns: {}
        plotParams: {1x0 cell array of 0 params}
          trainFcn: (none)
        trainParam: (none)
 
    weight and bias values:
 
                IW: {0x0 cell} containing 0 input weight matrices
                LW: {0x0 cell} containing 0 layer weight matrices
                 b: {0x1 cell} containing 0 bias vectors
 
    methods:
 
             adapt: Learn while in continuous use
         configure: Configure inputs &amp; outputs
            gensim: Generate Simulink model
              init: Initialize weights &amp; biases
           perform: Calculate performance
               sim: Evaluate network outputs given inputs
             train: Train network with examples
              view: View diagram
       unconfigure: Unconfigure inputs &amp; outputs
 
</pre><h2>&#36755;&#20837;&#19982;&#32593;&#32476;&#23618;&#25968;&#23450;&#20041;<a name="4"></a></h2><pre class="codeinput">net.numInputs = 2;
net.numLayers = 3;
</pre><h2>&#20351;&#29992;view(net)&#35266;&#23519;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#12290;<a name="5"></a></h2><pre class="codeinput">view(net)
<span class="comment">% &#27492;&#26102;&#31070;&#32463;&#32593;&#32476;&#26377;&#20004;&#20010;&#36755;&#20837;&#65292;&#19977;&#20010;&#31070;&#32463;&#20803;&#23618;&#12290;&#20294;&#35831;&#27880;&#24847;&#65306;net.numInputs&#35774;&#32622;&#30340;&#26159;</span>
<span class="comment">% &#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#20010;&#25968;&#65292;&#27599;&#20010;&#36755;&#20837;&#30340;&#32500;&#25968;&#26159;&#30001;net.inputs{i}.size&#25511;&#21046;&#12290;</span>
</pre><img vspace="5" hspace="5" src="chapter41_01.png" alt=""> <h2>&#38408;&#20540;&#36830;&#25509;&#23450;&#20041;<a name="6"></a></h2><pre class="codeinput">net.biasConnect(1) = 1;
net.biasConnect(3) = 1;
<span class="comment">% &#25110;&#32773;&#20351;&#29992;net.biasConnect = [1; 0; 1];</span>
view(net)
</pre><img vspace="5" hspace="5" src="chapter41_02.png" alt=""> <h2>&#36755;&#20837;&#19982;&#23618;&#36830;&#25509;&#23450;&#20041;<a name="7"></a></h2><pre class="codeinput">net.inputConnect(1,1) = 1;
net.inputConnect(2,1) = 1;
net.inputConnect(2,2) = 1;
<span class="comment">% &#25110;&#32773;&#20351;&#29992;net.inputConnect = [1 0; 1 1; 0 0];</span>
view(net)
net.layerConnect = [0 0 0; 0 0 0; 1 1 1];
view(net)
</pre><img vspace="5" hspace="5" src="chapter41_03.png" alt=""> <img vspace="5" hspace="5" src="chapter41_04.png" alt=""> <h2>&#36755;&#20986;&#36830;&#25509;&#35774;&#32622;<a name="8"></a></h2><pre class="codeinput">net.outputConnect = [0 1 1];
view(net)
</pre><img vspace="5" hspace="5" src="chapter41_05.png" alt=""> <h2>&#36755;&#20837;&#35774;&#32622;<a name="9"></a></h2><pre class="codeinput">net.inputs
net.inputs{1}
net.inputs{1}.processFcns = {<span class="string">'removeconstantrows'</span>,<span class="string">'mapminmax'</span>};
net.inputs{2}.size = 5;
net.inputs{1}.exampleInput = [0 10 5; 0 3 10];
view(net)
</pre><pre class="codeoutput">
ans = 

    [1x1 nnetInput]
    [1x1 nnetInput]


ans = 

    Neural Network Input

              name: 'Input'
    feedbackOutput: []
       processFcns: {}
     processParams: {1x0 cell array of 0 params}
   processSettings: {0x0 cell array of 0 settings}
    processedRange: []
     processedSize: 0
             range: []
              size: 0
          userdata: (your custom info)

</pre><img vspace="5" hspace="5" src="chapter41_06.png" alt=""> <h2>&#23618;&#35774;&#32622;<a name="10"></a></h2><pre class="codeinput">net.layers{1}
<span class="comment">% &#23558;&#31070;&#32463;&#32593;&#32476;&#31532;&#19968;&#23618;&#30340;&#31070;&#32463;&#20803;&#20010;&#25968;&#35774;&#32622;&#20026;4&#20010;&#65292;&#20854;&#20256;&#36882;&#20989;&#25968;&#35774;&#32622;&#20026;&#8220;tansig&#8221;&#24182;</span>
<span class="comment">% &#23558;&#20854;&#21021;&#22987;&#21270;&#20989;&#25968;&#35774;&#32622;&#20026;Nguyen-Widrow&#20989;&#25968;&#12290;</span>
net.layers{1}.size = 4;
net.layers{1}.transferFcn = <span class="string">'tansig'</span>;
net.layers{1}.initFcn = <span class="string">'initnw'</span>;
<span class="comment">% &#23558;&#31532;&#20108;&#23618;&#31070;&#32463;&#20803;&#20010;&#25968;&#35774;&#32622;&#20026;3&#20010;&#65292;&#20854;&#20256;&#36882;&#20989;&#25968;&#35774;&#32622;&#20026;&#8220;logsig&#8221;&#65292;&#24182;&#20351;&#29992;&#8220;initnw&#8221;&#21021;&#22987;&#21270;&#12290;</span>
net.layers{2}.size = 3;
net.layers{2}.transferFcn = <span class="string">'logsig'</span>;
net.layers{2}.initFcn = <span class="string">'initnw'</span>;
<span class="comment">% &#23558;&#31532;&#19977;&#23618;&#21021;&#22987;&#21270;&#20989;&#25968;&#35774;&#32622;&#20026;&#8220;initnw&#8221;</span>
net.layers{3}.initFcn = <span class="string">'initnw'</span>;
view(net)
</pre><pre class="codeoutput">
ans = 

    Neural Network Layer
 
              name: 'Layer'
        dimensions: 0
       distanceFcn: (none)
     distanceParam: (none)
         distances: []
           initFcn: 'initwb'
       netInputFcn: 'netsum'
     netInputParam: (none)
         positions: []
             range: []
              size: 0
       topologyFcn: (none)
       transferFcn: 'purelin'
     transferParam: (none)
          userdata: (your custom info)
 
</pre><img vspace="5" hspace="5" src="chapter41_07.png" alt=""> <h2>&#36755;&#20986;&#35774;&#32622;<a name="11"></a></h2><pre class="codeinput">net.outputs
net.outputs{2}
</pre><pre class="codeoutput">
ans = 

    []    [1x1 nnetOutput]    [1x1 nnetOutput]


ans = 

    Neural Network Output

              name: 'Output'
     feedbackInput: []
     feedbackDelay: 0
      feedbackMode: 'none'
       processFcns: {}
     processParams: {1x0 cell array of 0 params}
   processSettings: {0x0 cell array of 0 settings}
    processedRange: [3x2 double]
     processedSize: 3
             range: [3x2 double]
              size: 3
          userdata: (your custom info)

</pre><h2>&#38408;&#20540;&#65292;&#36755;&#20837;&#26435;&#20540;&#19982;&#23618;&#26435;&#20540;&#35774;&#32622;<a name="12"></a></h2><pre class="codeinput">net.biases
net.biases{1}
net.inputWeights
net.layerWeights
</pre><pre class="codeoutput">
ans = 

    [1x1 nnetBias]
    []
    [1x1 nnetBias]


ans = 

    Neural Network Bias

           initFcn: (none)
             learn: true
          learnFcn: (none)
        learnParam: (none)
              size: 4
          userdata: (your custom info)


ans = 

    [1x1 nnetWeight]                  []
    [1x1 nnetWeight]    [1x1 nnetWeight]
                  []                  []


ans = 

                  []                  []                  []
                  []                  []                  []
    [1x1 nnetWeight]    [1x1 nnetWeight]    [1x1 nnetWeight]

</pre><h2>&#23558;&#31070;&#32463;&#32593;&#32476;&#30340;&#26576;&#20123;&#26435;&#20540;&#30340;&#24310;&#36831;&#36827;&#34892;&#35774;&#32622;<a name="13"></a></h2><pre class="codeinput">net.inputWeights{2,1}.delays = [0 1];
net.inputWeights{2,2}.delays = 1;
net.layerWeights{3,3}.delays = 1;
</pre><h2>&#32593;&#32476;&#20989;&#25968;&#35774;&#32622;<a name="14"></a></h2><p>&#23558;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#35774;&#32622;&#20026;&#8220;initlay&#8221;&#65292;&#36825;&#26679;&#31070;&#32463;&#32593;&#32476;&#23601;&#21487;&#20197;&#25353;&#29031; &#25105;&#20204;&#35774;&#32622;&#30340;&#23618;&#21021;&#22987;&#21270;&#20989;&#25968;&#8220; initnw&#8221;&#21363;Nguyen-Widrow&#36827;&#34892;&#21021;&#22987;&#21270;&#12290;</p><pre class="codeinput">net.initFcn = <span class="string">'initlay'</span>;
<span class="comment">% &#23558;&#31070;&#32463;&#32593;&#32476;&#30340;&#35823;&#24046;&#35774;&#32622;&#20026;&#8220;mse&#8221;&#65288;mean squared error&#65289;&#65292;&#21516;&#26102;&#23558;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#20989;&#25968;</span>
<span class="comment">% &#35774;&#32622;&#20026;&#8220;trainlm&#8221;Levenberg-Marquardt backpropagation)&#12290;</span>
net.performFcn = <span class="string">'mse'</span>;
net.trainFcn = <span class="string">'trainlm'</span>;
<span class="comment">% &#20026;&#20102;&#20351;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#38543;&#26426;&#21010;&#20998;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;divideFcn&#35774;&#32622;&#20026;&#8220;dividerand&#8221;&#12290;</span>
net.divideFcn = <span class="string">'dividerand'</span>;
<span class="comment">% &#23558; plot functions&#35774;&#32622;&#20026;&#65306;&#8220;plotperform&#8221;,&#8220;plottrainstate&#8221;</span>
net.plotFcns = {<span class="string">'plotperform'</span>,<span class="string">'plottrainstate'</span>};
</pre><h2>&#26435;&#20540;&#38408;&#20540;&#22823;&#23567;&#35774;&#32622;<a name="15"></a></h2><pre class="codeinput">net.IW{1,1}, net.IW{2,1}, net.IW{2,2}
net.LW{3,1}, net.LW{3,2}, net.LW{3,3}
net.b{1}, net.b{3}
</pre><pre class="codeoutput">
ans =

     0     0
     0     0
     0     0
     0     0


ans =

     0     0     0     0
     0     0     0     0
     0     0     0     0


ans =

     0     0     0     0     0
     0     0     0     0     0
     0     0     0     0     0


ans =

   Empty matrix: 0-by-4


ans =

   Empty matrix: 0-by-3


ans =

     []


ans =

     0
     0
     0
     0


ans =

   Empty matrix: 0-by-1

</pre><h2>&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;<a name="16"></a></h2><pre class="codeinput">net = init(net);
net.IW{1,1}
</pre><pre class="codeoutput">
ans =

   -2.7851    0.2880
    2.1169   -1.8327
    0.6403   -2.7258
   -1.8147    2.1323

</pre><h2>&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;<a name="17"></a></h2><pre class="codeinput">X = {[0; 0] [2; 0.5]; [2; -2; 1; 0; 1] [-1; -1; 1; 0; 1]};
T = {[1; 1; 1] [0; 0; 0]; 1 -1};
Y = sim(net,X)
</pre><pre class="codeoutput">
Y = 

    [3x1 double]    [3x1 double]
    [0x1 double]    [0x1 double]

</pre><h2>&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21442;&#25968;<a name="18"></a></h2><pre class="codeinput">net.trainParam
</pre><pre class="codeoutput">
ans = 

 
    Function Parameters for 'trainlm'
 
    Show Training Window Feedback   showWindow: true
    Show Command Line Feedback showCommandLine: false
    Command Line Frequency                show: 25
    Maximum Epochs                      epochs: 1000
    Maximum Training Time                 time: Inf
    Performance Goal                      goal: 0
    Minimum Gradient                  min_grad: 1e-07
    Maximum Validation Checks         max_fail: 6
    Mu                                      mu: 0.001
    Mu Decrease Ratio                   mu_dec: 0.1
    Mu Increase Ratio                   mu_inc: 10
    Maximum mu                          mu_max: 10000000000
 
</pre><h2>&#35757;&#32451;&#32593;&#32476;<a name="19"></a></h2><pre class="codeinput">net = train(net,X,T);
</pre><h2>&#20223;&#30495;&#26469;&#26816;&#26597;&#31070;&#32463;&#32593;&#32476;&#26159;&#21542;&#30456;&#24212;&#27491;&#24120;&#12290;<a name="20"></a></h2><pre class="codeinput">Y = sim(net,X)
</pre><pre class="codeoutput">
Y = 

    [3x1 double]    [3x1 double]
    [    1.0000]    [   -1.0000]

</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2012b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Matlab神经网络43个案例分析

% 定制神经网络的实现-神经网络的个性化建模与仿真
% by 王小川(@王小川_matlab)
% http://www.matlabsky.com
% Email:sina363@163.com
% http://weibo.com/hgsz2003

%% 清空环境变量
clear all
clc
warning off
%% 建立一个“空”神经网络
net = network

%% 输入与网络层数定义 
net.numInputs = 2;
net.numLayers = 3;

%% 使用view(net)观察神经网络结构。
view(net)
% 此时神经网络有两个输入，三个神经元层。但请注意：net.numInputs设置的是
% 神经网络的输入个数，每个输入的维数是由net.inputs{i}.size控制。

%%  阈值连接定义
net.biasConnect(1) = 1;
net.biasConnect(3) = 1;
% 或者使用net.biasConnect = [1; 0; 1];
view(net)

%% 输入与层连接定义
net.inputConnect(1,1) = 1;
net.inputConnect(2,1) = 1;
net.inputConnect(2,2) = 1;
% 或者使用net.inputConnect = [1 0; 1 1; 0 0];
view(net)
net.layerConnect = [0 0 0; 0 0 0; 1 1 1];
view(net)
%% 输出连接设置 
net.outputConnect = [0 1 1];
view(net)

%% 输入设置
net.inputs
net.inputs{1}
net.inputs{1}.processFcns = {'removeconstantrows','mapminmax'};
net.inputs{2}.size = 5;
net.inputs{1}.exampleInput = [0 10 5; 0 3 10];
view(net)

%% 层设置
net.layers{1}
% 将神经网络第一层的神经元个数设置为4个，其传递函数设置为“tansig”并
% 将其初始化函数设置为Nguyen-Widrow函数。
net.layers{1}.size = 4;
net.layers{1}.transferFcn = 'tansig';
net.layers{1}.initFcn = 'initnw';
% 将第二层神经元个数设置为3个，其传递函数设置为“logsig”，并使用“initnw”初始化。
net.layers{2}.size = 3;
net.layers{2}.transferFcn = 'logsig';
net.layers{2}.initFcn = 'initnw';
% 将第三层初始化函数设置为“initnw”
net.layers{3}.initFcn = 'initnw';
view(net)

%% 输出设置
net.outputs
net.outputs{2}

%% 阈值，输入权值与层权值设置
net.biases
net.biases{1}
net.inputWeights
net.layerWeights

%% 将神经网络的某些权值的延迟进行设置 
net.inputWeights{2,1}.delays = [0 1];
net.inputWeights{2,2}.delays = 1;
net.layerWeights{3,3}.delays = 1;

%% 网络函数设置
% 将神经网络初始化设置为“initlay”，这样神经网络就可以按照
% 我们设置的层初始化函数“ initnw”即Nguyen-Widrow进行初始化。
net.initFcn = 'initlay';
% 将神经网络的误差设置为“mse”（mean squared error），同时将神经网络的训练函数
% 设置为“trainlm”Levenberg-Marquardt backpropagation)。
net.performFcn = 'mse';
net.trainFcn = 'trainlm';
% 为了使神经网络可以随机划分训练数据集，我们可以将divideFcn设置为“dividerand”。
net.divideFcn = 'dividerand';
% 将 plot functions设置为：“plotperform”,“plottrainstate”
net.plotFcns = {'plotperform','plottrainstate'};

%% 权值阈值大小设置
net.IW{1,1}, net.IW{2,1}, net.IW{2,2}
net.LW{3,1}, net.LW{3,2}, net.LW{3,3}
net.b{1}, net.b{3}

%% 神经网络初始化
net = init(net);
net.IW{1,1}

%% 神经网络的训练
X = {[0; 0] [2; 0.5]; [2; -2; 1; 0; 1] [-1; -1; 1; 0; 1]};
T = {[1; 1; 1] [0; 0; 0]; 1 -1};
Y = sim(net,X)

%% 神经网络的训练参数
net.trainParam

%%  训练网络
net = train(net,X,T);

%% 仿真来检查神经网络是否相应正常。
Y = sim(net,X)
##### SOURCE END #####
--></body></html>